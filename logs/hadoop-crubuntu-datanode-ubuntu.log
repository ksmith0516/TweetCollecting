2017-09-07 19:10:51,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = crubuntu
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.51.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.24.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/objenesis-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-07 19:10:51,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-07 19:10:58,085 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-07 19:10:58,895 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-07 19:10:58,895 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2017-09-07 19:10:58,940 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2017-09-07 19:10:58,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2017-09-07 19:10:58,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2017-09-07 19:10:59,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2017-09-07 19:10:59,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2017-09-07 19:10:59,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2017-09-07 19:11:00,164 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-07 19:11:00,218 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-07 19:11:00,257 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2017-09-07 19:11:00,286 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-07 19:11:00,293 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-09-07 19:11:00,293 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-07 19:11:00,294 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-07 19:11:00,398 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41359
2017-09-07 19:11:00,398 INFO org.mortbay.log: jetty-6.1.26
2017-09-07 19:11:01,428 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41359
2017-09-07 19:11:04,279 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2017-09-07 19:11:04,300 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-07 19:11:04,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = crubuntu
2017-09-07 19:11:04,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2017-09-07 19:11:05,257 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-07 19:11:05,537 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2017-09-07 19:11:06,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2017-09-07 19:11:07,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2017-09-07 19:11:07,056 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-09-07 19:11:07,168 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2017-09-07 19:11:07,182 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2017-09-07 19:11:07,192 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2017-09-07 19:11:07,194 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2017-09-07 19:11:07,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2017-09-07 19:11:07,252 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
	at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:579)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:152)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1314)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:481)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2601)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2489)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2536)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2721)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2745)
2017-09-07 19:11:07,295 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2017-09-07 19:11:07,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2017-09-07 19:15:31,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = crubuntu
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.51.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.24.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/objenesis-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-07 19:15:31,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-07 19:15:37,276 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-07 19:15:38,086 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-07 19:15:38,087 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2017-09-07 19:15:38,135 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2017-09-07 19:15:38,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2017-09-07 19:15:38,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2017-09-07 19:15:38,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2017-09-07 19:15:38,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2017-09-07 19:15:38,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2017-09-07 19:15:39,384 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-07 19:15:39,447 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-07 19:15:39,530 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2017-09-07 19:15:39,561 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-07 19:15:39,585 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-09-07 19:15:39,586 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-07 19:15:39,586 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-07 19:15:39,685 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39073
2017-09-07 19:15:39,685 INFO org.mortbay.log: jetty-6.1.26
2017-09-07 19:15:40,412 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39073
2017-09-07 19:15:41,529 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2017-09-07 19:15:41,565 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-07 19:15:41,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = crubuntu
2017-09-07 19:15:41,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2017-09-07 19:15:42,368 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-07 19:15:42,623 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2017-09-07 19:15:43,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2017-09-07 19:15:43,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2017-09-07 19:15:43,532 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-09-07 19:15:43,638 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2017-09-07 19:15:43,641 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2017-09-07 19:15:43,644 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2017-09-07 19:15:43,645 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2017-09-07 19:15:43,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2017-09-07 19:15:43,682 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
	at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:579)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:152)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1314)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:481)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2601)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2489)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2536)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2721)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2745)
2017-09-07 19:15:43,707 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2017-09-07 19:15:43,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2017-09-07 19:18:02,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = crubuntu
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.51.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.24.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/objenesis-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-07 19:18:02,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-07 19:18:08,616 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-07 19:18:09,388 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-07 19:18:09,388 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2017-09-07 19:18:09,453 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2017-09-07 19:18:09,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2017-09-07 19:18:09,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2017-09-07 19:18:09,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2017-09-07 19:18:09,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2017-09-07 19:18:09,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2017-09-07 19:18:10,866 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-07 19:18:10,946 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-07 19:18:10,994 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2017-09-07 19:18:11,028 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-07 19:18:11,049 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-09-07 19:18:11,051 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-07 19:18:11,051 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-07 19:18:11,156 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 43633
2017-09-07 19:18:11,156 INFO org.mortbay.log: jetty-6.1.26
2017-09-07 19:18:11,813 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:43633
2017-09-07 19:18:13,007 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2017-09-07 19:18:13,032 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-07 19:18:13,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = crubuntu
2017-09-07 19:18:13,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2017-09-07 19:18:13,751 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-07 19:18:13,984 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2017-09-07 19:18:14,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2017-09-07 19:18:14,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2017-09-07 19:18:14,589 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-09-07 19:18:14,596 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2017-09-07 19:18:14,598 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2017-09-07 19:18:14,599 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2017-09-07 19:18:14,600 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2017-09-07 19:18:14,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2017-09-07 19:18:14,627 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
	at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:579)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:152)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1314)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:481)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2601)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2489)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2536)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2721)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2745)
2017-09-07 19:18:14,646 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2017-09-07 19:18:14,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2017-09-07 19:45:59,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = crubuntu
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.51.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.24.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/objenesis-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-07 19:45:59,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-07 19:46:04,930 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-07 19:46:05,722 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-07 19:46:05,723 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2017-09-07 19:46:05,764 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2017-09-07 19:46:05,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2017-09-07 19:46:05,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2017-09-07 19:46:06,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2017-09-07 19:46:06,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2017-09-07 19:46:06,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2017-09-07 19:46:06,974 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-07 19:46:07,033 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-07 19:46:07,091 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2017-09-07 19:46:07,136 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-07 19:46:07,149 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-09-07 19:46:07,150 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-07 19:46:07,150 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-07 19:46:07,237 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 38385
2017-09-07 19:46:07,237 INFO org.mortbay.log: jetty-6.1.26
2017-09-07 19:46:08,136 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:38385
2017-09-07 19:46:09,411 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2017-09-07 19:46:09,444 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-07 19:46:09,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = crubuntu
2017-09-07 19:46:09,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2017-09-07 19:46:09,897 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-07 19:46:09,987 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2017-09-07 19:46:10,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2017-09-07 19:46:10,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2017-09-07 19:46:10,478 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-09-07 19:46:10,478 WARN org.apache.hadoop.http.HttpServer2: HttpServer Acceptor: isRunning is false. Rechecking.
2017-09-07 19:46:10,482 WARN org.apache.hadoop.http.HttpServer2: HttpServer Acceptor: isRunning is false
2017-09-07 19:46:10,586 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2017-09-07 19:46:10,608 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2017-09-07 19:46:10,611 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2017-09-07 19:46:10,616 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2017-09-07 19:46:10,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2017-09-07 19:46:10,652 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
	at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:579)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:152)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1314)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:481)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2601)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2489)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2536)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2721)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2745)
2017-09-07 19:46:10,670 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2017-09-07 19:46:10,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2017-09-07 19:49:57,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = crubuntu
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.51.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.24.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/objenesis-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-07 19:49:57,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-07 19:50:02,615 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-07 19:50:03,277 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-07 19:50:03,277 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2017-09-07 19:50:03,319 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2017-09-07 19:50:03,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2017-09-07 19:50:03,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2017-09-07 19:50:03,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2017-09-07 19:50:03,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2017-09-07 19:50:03,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2017-09-07 19:50:04,450 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-07 19:50:04,524 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-07 19:50:04,574 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2017-09-07 19:50:04,605 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-07 19:50:04,614 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-09-07 19:50:04,614 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-07 19:50:04,615 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-07 19:50:04,713 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40405
2017-09-07 19:50:04,714 INFO org.mortbay.log: jetty-6.1.26
2017-09-07 19:50:05,471 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40405
2017-09-07 19:50:06,764 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2017-09-07 19:50:06,796 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-07 19:50:06,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = crubuntu
2017-09-07 19:50:06,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2017-09-07 19:50:07,268 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-07 19:50:07,357 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2017-09-07 19:50:07,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2017-09-07 19:50:07,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2017-09-07 19:50:07,893 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-09-07 19:50:08,003 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2017-09-07 19:50:08,008 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2017-09-07 19:50:08,015 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2017-09-07 19:50:08,015 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2017-09-07 19:50:08,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2017-09-07 19:50:08,046 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
	at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:579)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:152)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1314)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:481)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2601)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2489)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2536)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2721)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2745)
2017-09-07 19:50:08,063 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2017-09-07 19:50:08,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2017-09-07 19:59:36,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = crubuntu
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.51.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.24.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/objenesis-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-07 19:59:36,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-07 19:59:41,381 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-07 19:59:42,075 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-07 19:59:42,075 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2017-09-07 19:59:42,117 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2017-09-07 19:59:42,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2017-09-07 19:59:42,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2017-09-07 19:59:42,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2017-09-07 19:59:42,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2017-09-07 19:59:42,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2017-09-07 19:59:43,262 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-07 19:59:43,328 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-07 19:59:43,380 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2017-09-07 19:59:43,411 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-07 19:59:43,432 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-09-07 19:59:43,433 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-07 19:59:43,433 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-07 19:59:43,533 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 38281
2017-09-07 19:59:43,533 INFO org.mortbay.log: jetty-6.1.26
2017-09-07 19:59:44,383 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:38281
2017-09-07 19:59:45,839 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2017-09-07 19:59:45,861 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-07 19:59:45,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = crubuntu
2017-09-07 19:59:45,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2017-09-07 19:59:46,300 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-07 19:59:46,390 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2017-09-07 19:59:46,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2017-09-07 19:59:46,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2017-09-07 19:59:56,856 WARN org.apache.hadoop.hdfs.DFSUtilClient: Namenode for null remains unresolved for ID null. Check your hdfs-site.xml file to ensure namenodes are configured properly.
2017-09-07 19:59:56,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2017-09-07 19:59:57,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to slave:9000 starting to offer service
2017-09-07 19:59:57,155 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-09-07 19:59:57,157 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-07 19:59:57,574 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:00:02,577 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:00:07,586 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:00:12,590 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:00:17,594 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:00:22,597 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:00:27,602 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:00:32,606 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:00:37,609 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:00:42,618 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:00:47,621 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:00:52,633 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:00:57,646 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:01:02,650 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:01:07,652 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:01:12,666 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:01:17,671 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:01:22,685 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:01:27,689 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:01:32,693 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:01:37,696 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:01:42,699 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:01:47,701 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:01:52,703 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:01:57,705 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:02:02,708 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:02:07,714 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:02:12,717 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:02:17,722 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:02:22,725 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:02:27,732 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:02:32,735 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:02:37,739 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:02:42,745 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:02:47,748 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:02:52,751 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:02:57,753 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:03:02,758 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:03:07,762 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:03:12,765 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:03:17,769 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:03:22,771 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:03:27,775 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:03:32,778 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:03:37,781 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:03:42,786 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:03:47,789 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:03:52,790 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:03:57,792 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:04:02,793 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:04:07,795 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:04:12,797 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:04:17,799 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:04:22,802 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:04:27,804 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:04:32,805 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:04:37,806 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:04:42,810 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:04:47,811 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:04:52,816 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:04:57,819 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:05:02,820 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:05:07,830 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:05:12,855 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:05:17,856 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:05:22,857 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:05:27,859 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:05:32,862 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:05:37,866 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:05:42,887 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:05:47,890 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:05:52,893 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:05:57,895 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:06:02,898 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:06:07,900 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:06:12,901 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:06:17,903 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:06:22,905 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:06:27,908 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:06:32,910 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:06:37,912 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:06:42,937 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:06:47,939 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:06:52,942 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:06:57,944 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:07:02,946 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:07:07,948 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:07:12,952 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:07:17,954 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:07:22,954 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:07:27,958 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:07:32,962 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:07:37,966 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:07:42,970 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:07:47,975 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:07:52,981 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:07:57,985 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:08:02,988 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:08:07,991 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:08:12,996 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:08:18,002 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:08:23,005 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:08:28,009 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:08:33,013 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:08:38,021 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:08:43,028 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:08:48,030 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:08:53,034 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:08:58,037 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:09:03,042 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:09:08,046 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:09:13,050 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:09:18,058 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:09:23,061 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:09:28,065 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:09:33,068 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:09:38,069 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:09:43,071 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:09:48,074 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:09:53,077 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:09:57,290 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:163)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:2942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-07 20:09:57,342 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses(DataNode.java:2922)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-07 20:09:58,081 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:10:03,084 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:10:08,095 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:10:13,099 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:10:18,113 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:10:23,117 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:10:28,122 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:10:33,126 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:10:38,130 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:10:43,134 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:10:48,137 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:10:53,138 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:10:58,139 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:11:03,144 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:11:08,146 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:11:13,150 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:11:18,153 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:11:23,159 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:11:28,163 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:11:33,166 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:11:38,169 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:11:43,172 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:11:48,177 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:11:53,180 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:11:58,184 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:12:03,187 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:12:08,189 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:12:13,191 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:12:18,194 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:12:23,198 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:12:28,201 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:12:33,203 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:12:38,205 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:12:43,207 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:12:48,211 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:12:53,215 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:12:58,217 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:13:03,221 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:13:08,224 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:13:13,229 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:13:18,234 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:13:23,238 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:13:28,242 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:13:33,246 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:13:38,249 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:13:43,253 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:13:48,257 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:13:53,261 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:13:58,265 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:14:03,269 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:14:08,272 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:14:13,278 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:14:18,282 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:14:23,285 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:14:28,287 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:14:33,291 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:14:38,302 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:14:43,304 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:14:48,310 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:14:53,321 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:14:58,323 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:15:03,326 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:15:08,329 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:15:13,333 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:15:18,336 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:15:23,339 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:15:28,341 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:15:33,342 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:15:38,344 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:15:43,346 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:15:48,349 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:15:53,352 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:15:58,354 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:16:03,357 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:16:08,360 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:16:13,362 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:16:18,364 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:16:23,365 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:16:28,366 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:16:33,367 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:16:38,369 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:16:43,372 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:16:48,375 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:16:53,378 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:16:58,383 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:17:03,386 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:17:08,389 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:17:13,393 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:17:18,401 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:17:23,403 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:17:28,404 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:17:33,406 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:17:38,411 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:17:43,418 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:17:48,420 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:17:53,422 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:17:58,425 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:18:03,426 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:18:08,430 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:18:13,434 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:18:18,437 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:18:23,439 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:18:28,442 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:18:33,445 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:18:38,448 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:18:43,450 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:18:48,451 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:18:53,455 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:18:58,461 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:19:03,465 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:19:08,468 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:19:13,470 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:19:18,471 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:19:23,473 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:19:28,482 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:19:33,501 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:19:38,507 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:19:43,515 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:19:48,517 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:19:53,519 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:19:57,456 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:163)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:2942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-07 20:19:57,465 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses(DataNode.java:2922)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-07 20:19:58,522 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:20:03,523 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:20:08,526 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:20:13,530 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:20:18,532 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:20:23,538 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:20:28,542 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:20:33,545 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:20:38,549 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:20:43,565 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:20:48,578 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:20:53,606 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:20:58,611 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:21:03,613 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:21:08,622 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:21:13,627 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:21:18,637 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:21:23,639 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:21:28,641 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:21:33,642 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:21:38,645 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:21:43,654 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:21:48,659 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:21:53,662 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:21:58,664 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:22:03,665 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:22:08,667 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:22:13,671 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:22:18,674 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:22:23,675 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:22:28,678 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:22:33,681 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:22:38,685 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:22:43,688 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:22:48,689 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:22:53,691 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:22:58,692 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:23:03,694 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:23:08,696 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:23:13,698 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:23:18,700 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:23:23,702 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:23:28,706 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:23:33,708 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:23:38,710 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:23:43,713 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:23:48,717 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:23:53,720 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:23:58,721 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:24:03,725 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:24:08,728 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:24:13,731 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:24:18,734 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:24:23,737 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:24:28,739 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:24:33,740 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:24:38,743 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:24:43,745 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:24:48,748 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:24:53,754 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:24:58,755 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:25:03,758 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:25:08,761 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:25:13,763 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:25:18,764 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:25:23,765 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:25:28,767 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:25:33,768 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:25:38,772 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:25:43,774 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:25:48,778 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:25:53,781 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:25:58,784 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:26:03,789 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:26:08,793 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:26:13,802 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:26:18,806 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:26:23,809 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:26:28,813 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:26:33,818 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:26:38,820 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:26:43,825 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:26:48,838 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:26:53,841 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:26:58,846 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:27:03,849 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:27:08,853 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:27:13,856 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:27:18,859 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:27:23,863 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:27:28,866 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:27:33,870 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:27:38,872 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:27:43,875 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:27:48,876 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:27:53,879 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:27:58,883 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:28:03,885 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:28:08,889 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:28:13,892 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:28:18,895 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:28:23,898 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:28:28,901 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:28:33,905 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:28:38,915 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:28:43,917 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:28:48,921 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:28:53,924 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:28:58,927 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:29:03,934 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:29:08,938 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:29:13,940 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:29:18,943 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:29:23,961 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:29:28,963 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:29:33,967 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:29:38,970 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:29:43,974 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:29:48,977 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:29:53,981 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:29:57,524 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:163)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:2942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-07 20:29:57,526 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses(DataNode.java:2922)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-07 20:29:58,985 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:30:03,989 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:30:08,991 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:30:13,993 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:30:18,995 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:30:23,996 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:30:28,997 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:30:34,000 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:30:39,002 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:30:44,006 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:30:49,009 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:30:54,010 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:30:59,012 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:31:04,018 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:31:09,032 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:31:14,039 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:31:19,040 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:31:27,040 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:31:32,041 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:31:37,042 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:31:42,043 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:31:47,045 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:31:52,046 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:31:57,047 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:32:02,049 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:32:07,051 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:32:12,051 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:32:17,053 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:32:22,053 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:32:27,055 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:32:32,056 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:32:37,057 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:32:42,058 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:32:47,059 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:32:52,060 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:32:57,062 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:33:02,064 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:33:07,065 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:33:12,067 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:33:17,070 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:33:22,076 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:33:27,079 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:33:32,081 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:33:37,082 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:33:42,085 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:33:47,087 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:33:52,089 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:33:57,091 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:34:02,093 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:34:07,094 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:34:12,097 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:34:17,099 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:34:22,101 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:34:27,102 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:34:32,104 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:34:37,106 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:34:42,111 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:34:47,113 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:34:52,115 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:34:57,117 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:35:02,119 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:35:07,121 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:35:12,123 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:35:17,125 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:35:22,126 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:35:27,128 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:35:32,130 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:35:37,131 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:35:42,133 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:35:47,135 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:35:52,136 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:35:57,137 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:36:02,138 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:36:07,138 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:36:12,139 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:36:17,140 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:36:22,142 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:36:27,143 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:36:32,144 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:36:37,145 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:36:42,148 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:36:47,150 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:36:52,152 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:36:57,155 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:37:02,156 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:37:07,161 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:37:12,163 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:37:17,165 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:37:22,167 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:37:27,170 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:37:32,171 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:37:37,172 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:37:42,174 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:37:47,175 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:37:52,176 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:37:57,177 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:38:02,178 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:38:07,179 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:38:12,180 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:38:17,181 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:38:22,182 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:38:27,684 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:38:32,685 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:38:37,686 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:38:42,687 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:38:47,689 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:38:52,789 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:38:57,790 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:39:02,791 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:39:07,792 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:39:12,792 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:39:17,794 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:39:22,795 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:39:27,796 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:39:32,797 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:39:37,798 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:39:42,798 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:39:47,799 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:39:52,800 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:39:57,802 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:40:00,556 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:163)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:2942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-07 20:40:00,558 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses(DataNode.java:2922)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-07 20:40:02,803 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:40:07,803 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:40:12,804 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:40:17,805 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:40:22,806 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:40:27,807 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:40:32,808 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:40:37,809 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:40:42,810 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:40:47,811 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:40:52,812 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:40:57,813 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:41:02,814 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:41:07,815 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:41:12,816 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:41:17,819 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:41:22,820 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:41:27,821 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:41:32,822 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:41:37,822 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:41:42,823 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:41:47,824 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:41:52,825 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:41:57,826 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:42:02,827 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:42:07,828 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:42:12,829 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:42:17,830 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:42:22,830 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:42:27,831 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:42:32,832 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:42:37,833 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:42:42,833 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:42:47,834 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:42:52,835 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:42:57,835 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:43:02,836 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:43:07,837 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:43:12,838 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:43:17,839 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:43:22,840 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:43:27,842 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:43:32,842 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:43:37,843 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:43:42,844 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:43:47,845 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:43:52,846 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:43:57,847 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:44:02,847 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:44:07,848 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:44:12,849 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:44:17,850 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:44:22,851 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:44:27,852 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:44:32,853 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:44:37,854 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:44:43,162 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:44:48,163 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:44:53,163 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:44:58,164 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:45:03,165 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:45:08,166 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:45:13,168 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:45:18,169 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:45:23,169 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:45:28,170 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:45:33,170 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:45:38,172 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:45:43,173 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:45:48,173 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:45:53,175 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:45:58,175 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:46:03,176 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:46:08,177 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:46:13,177 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:46:18,178 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:46:23,178 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:46:28,179 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:46:33,180 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:46:38,181 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:46:43,182 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:46:48,183 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:46:53,184 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:46:58,185 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:47:03,187 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:47:08,188 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:47:13,189 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:47:18,190 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:47:23,191 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:47:28,191 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:47:33,193 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:47:38,194 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:47:43,195 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:47:48,196 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:47:53,197 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:47:58,198 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:48:03,199 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:48:08,200 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:48:13,201 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:48:18,201 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:48:23,202 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:48:28,203 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:48:33,204 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:48:38,205 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:48:43,206 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:48:48,206 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:48:53,207 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:48:58,207 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:49:03,208 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:49:08,209 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:49:13,210 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:49:18,211 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:49:23,212 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:49:28,212 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:49:33,213 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:49:38,574 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:49:43,575 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:49:48,576 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:49:53,577 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:49:55,830 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1246ms
No GCs detected
2017-09-07 20:50:00,582 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:163)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:2942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-07 20:50:00,584 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses(DataNode.java:2922)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-07 20:50:00,830 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:50:05,832 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:50:10,834 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:50:15,834 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:50:20,836 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:50:25,837 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:50:30,838 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:50:35,840 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:50:40,841 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:50:45,842 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:50:50,843 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:50:55,843 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:51:00,844 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:51:05,845 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:51:10,845 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:51:15,846 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:51:20,847 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:51:25,849 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:51:30,857 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:51:35,858 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:51:40,860 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:51:45,862 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:51:50,863 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:51:55,994 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:52:00,995 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:52:05,996 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:52:10,998 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:52:15,999 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:52:21,004 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:52:26,008 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:52:31,010 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:52:36,011 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:52:41,014 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:52:46,015 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:52:51,017 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:52:56,056 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:53:01,058 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:53:06,059 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:53:11,062 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:53:16,065 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:53:21,068 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:53:26,069 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:53:31,071 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:53:36,073 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:53:41,076 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:53:46,078 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:53:51,079 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:53:56,081 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:54:01,083 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:54:06,084 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:54:11,085 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:54:16,090 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:54:21,092 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:54:26,093 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:54:31,095 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:54:36,096 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:54:41,098 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:54:46,099 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:54:51,101 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:54:56,102 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:55:01,104 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:55:06,106 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:55:11,107 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:55:16,109 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:55:21,111 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:55:26,112 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:55:31,114 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:55:36,115 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 20:55:41,116 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:05:23,277 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:05:28,277 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:05:33,278 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:05:38,280 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:05:43,280 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:05:48,281 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:05:52,859 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:05:57,860 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:06:02,861 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:06:07,862 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:06:12,864 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:06:17,865 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:06:22,866 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:06:27,867 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:06:32,868 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-07 21:06:37,869 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:38:09,284 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:38:14,356 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:38:19,360 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:38:24,361 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:38:29,363 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:38:34,364 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:38:39,380 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:38:44,384 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:38:49,387 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:38:54,390 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:38:59,400 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:39:04,403 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:39:09,406 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:39:14,409 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:39:19,411 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:39:24,416 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:39:29,418 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:39:34,419 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:39:39,421 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:39:44,423 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:39:49,425 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:39:54,427 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:39:59,429 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:40:04,432 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:40:09,434 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:40:14,436 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:40:19,438 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:40:24,441 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:40:29,443 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:40:34,445 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:40:39,448 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:40:44,450 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:40:49,461 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:40:54,463 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:40:59,465 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:41:03,737 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:163)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:2942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-10 08:41:03,747 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses(DataNode.java:2922)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-10 08:41:04,467 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:41:09,469 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:41:14,471 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:41:19,482 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:41:24,484 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:41:29,485 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:41:34,487 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:41:39,489 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:41:44,491 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:41:49,493 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:41:54,494 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:41:59,504 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:42:04,514 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:42:09,520 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:42:14,522 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:42:19,524 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:42:24,525 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:42:29,528 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:42:34,530 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:42:39,531 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:42:44,532 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:42:49,533 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:42:54,534 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:42:59,534 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:43:04,535 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:43:09,536 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:43:14,537 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:43:19,540 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:43:24,542 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:43:29,596 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:43:34,662 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:43:39,663 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:43:44,665 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:43:49,668 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:43:54,670 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:43:59,673 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:44:04,676 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:44:09,678 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:44:14,681 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:44:19,683 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:44:24,683 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:44:29,689 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:44:34,833 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:44:39,838 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:44:44,853 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:44:49,856 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:44:54,859 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:44:59,861 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:45:04,874 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:45:09,876 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:45:14,878 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:45:19,881 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:45:24,883 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:45:29,884 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:45:34,991 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:45:39,993 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:45:44,995 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:45:49,997 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:45:54,999 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:46:00,001 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:46:05,003 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:46:10,005 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:46:15,008 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:46:20,047 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:46:25,048 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:46:30,048 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:46:35,049 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:46:40,051 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:46:45,052 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:46:50,056 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:46:55,058 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:47:00,060 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:47:05,061 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:47:10,063 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:47:15,065 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:47:20,067 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:47:25,069 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:47:30,071 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:47:35,073 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:47:40,075 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:47:45,077 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:47:50,079 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:47:55,081 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:48:00,091 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:48:05,093 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:48:10,095 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:48:15,097 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:48:20,099 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:48:25,101 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:48:30,102 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:48:35,104 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:48:40,105 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:48:45,107 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:48:50,109 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:48:55,112 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:49:00,113 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:49:05,115 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:49:10,117 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:49:15,118 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:49:20,141 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:49:25,143 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:49:30,144 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:49:35,146 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:49:40,148 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:49:45,149 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:49:50,151 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:49:55,152 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:50:00,154 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:50:05,155 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:50:10,157 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:50:15,159 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:50:20,160 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:50:25,163 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:50:30,165 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:50:35,167 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:50:40,168 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:50:45,171 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:50:50,174 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:50:55,174 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:51:00,175 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:51:03,802 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:163)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:2942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-10 08:51:03,805 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses(DataNode.java:2922)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-10 08:51:05,176 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:51:10,177 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:51:15,178 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:51:20,178 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:51:25,180 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:51:30,181 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:51:35,182 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:51:40,183 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:51:45,187 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:51:50,190 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:51:55,194 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:52:00,195 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:52:05,197 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:52:10,200 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:52:15,227 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:52:20,271 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:52:25,274 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:52:30,277 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:52:35,278 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:52:40,279 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:52:45,281 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:52:50,283 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:52:55,285 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:53:00,362 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:53:05,422 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:53:10,424 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:53:15,426 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:53:20,428 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:53:25,430 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:53:30,432 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:53:35,434 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:53:40,436 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:53:45,437 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:53:50,439 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:53:55,441 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:54:00,442 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:54:05,444 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:54:10,447 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:54:15,448 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:54:20,449 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:54:25,450 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:54:30,472 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:54:35,474 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:54:40,475 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:54:45,478 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:54:50,479 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:54:55,481 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:55:00,483 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:55:05,485 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:55:10,486 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:55:15,489 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:55:20,491 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:55:25,493 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:55:30,497 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:55:35,500 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:55:40,502 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:55:45,503 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:55:50,505 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:55:55,507 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:56:00,509 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:56:05,511 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:56:10,513 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:56:15,517 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:56:20,518 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:56:25,524 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:56:30,525 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:56:35,526 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:56:40,528 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:56:45,530 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:56:50,531 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:56:55,533 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:57:00,535 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:57:05,537 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:57:10,539 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:57:15,540 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:57:20,546 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:57:25,554 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:57:30,562 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:57:35,564 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:57:40,566 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:57:45,568 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:57:50,569 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:57:55,571 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:58:00,572 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:58:05,574 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:58:10,575 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:58:15,577 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:58:20,579 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:58:25,581 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:58:30,584 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:58:35,585 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:58:40,588 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:58:45,589 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:58:50,592 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:58:55,594 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:59:00,596 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:59:05,597 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:59:10,599 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:59:15,601 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:59:20,602 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:59:25,603 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:59:30,603 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:59:35,605 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:59:40,608 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:59:45,609 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:59:50,609 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 08:59:55,614 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:00:00,615 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:00:05,616 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:00:10,617 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:00:15,618 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:00:20,622 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:00:25,624 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:00:30,627 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:00:35,629 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:00:40,633 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:00:45,634 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:00:50,637 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:00:55,638 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:01:00,640 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:01:03,852 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:163)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:2942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-10 09:01:03,858 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses(DataNode.java:2922)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-10 09:01:05,642 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:01:10,645 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:01:15,647 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:01:20,650 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:01:25,653 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:01:30,654 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:01:35,657 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:01:40,659 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:01:45,661 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:01:50,663 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:01:55,665 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:02:00,666 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:02:05,668 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:02:10,669 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:02:15,670 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:02:20,676 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:02:25,686 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:02:30,687 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:02:35,694 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:02:40,700 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:02:45,702 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:02:50,704 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:02:55,707 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:03:00,711 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:03:05,713 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:03:10,714 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:03:15,715 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:03:20,717 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:03:25,719 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:03:30,721 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:03:35,725 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:03:40,727 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:03:45,729 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:03:50,731 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:03:55,732 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:04:00,804 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:04:05,805 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:04:10,807 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:04:15,815 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:04:20,817 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:04:25,820 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:04:30,827 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:04:35,829 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:04:40,830 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:04:45,832 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:04:50,836 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:04:55,837 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:05:00,839 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:05:05,842 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:05:10,845 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:05:15,846 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:05:20,849 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:05:25,851 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:05:30,855 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:05:35,856 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:05:40,859 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:05:45,861 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:05:50,864 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:05:55,866 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:06:00,869 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:06:05,871 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:06:10,873 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:06:15,875 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:06:20,877 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:06:25,879 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:06:30,881 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:06:35,885 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:06:40,887 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:06:45,888 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:06:50,890 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:06:55,893 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:07:00,895 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:07:05,896 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:07:10,898 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:07:15,900 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:07:20,902 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:07:25,903 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:07:30,906 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:07:35,907 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:07:40,909 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:07:45,910 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:07:50,912 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:07:55,914 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:08:00,915 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:08:05,916 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:08:10,918 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:08:15,919 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:08:20,921 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:08:25,923 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:08:30,925 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:08:35,926 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:08:40,927 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:08:45,929 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:08:50,931 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:08:55,934 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:09:00,936 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:09:05,937 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:09:10,939 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:09:15,941 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:09:20,943 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:09:25,945 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:09:30,946 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:09:35,947 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:09:40,949 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:09:45,950 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:09:50,951 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:09:55,967 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:10:00,968 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:10:05,972 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:10:10,973 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:10:15,976 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:10:20,977 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:10:25,978 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:10:30,980 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:10:35,981 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:10:40,983 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:10:45,985 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:10:50,998 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:10:56,005 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:11:01,007 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:11:03,918 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:163)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:2942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-10 09:11:03,923 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses(DataNode.java:2922)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-10 09:11:06,009 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:11:11,011 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:11:16,014 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:11:21,017 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:11:26,019 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:11:31,021 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:11:36,021 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:11:41,023 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:11:46,024 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:11:51,026 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:11:56,030 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:12:01,033 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:12:06,035 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:12:11,039 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:12:16,044 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:12:21,045 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:12:26,048 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:12:31,051 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:12:36,053 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:12:41,055 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:12:46,057 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:12:51,065 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:12:56,073 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:13:01,076 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:13:06,159 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:13:11,160 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:13:16,165 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:13:21,167 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:13:26,169 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:13:31,171 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:13:36,173 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:13:41,174 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:13:46,176 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:13:51,178 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:13:56,182 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:14:01,183 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:14:06,185 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:14:11,187 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:14:16,188 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:14:21,190 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:14:26,192 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:14:31,193 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:14:36,195 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:14:41,198 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:14:46,200 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:14:51,202 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:14:56,210 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:15:01,212 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:15:06,214 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:15:11,217 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:15:16,219 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:15:21,222 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:15:26,223 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:15:31,225 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:15:36,226 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:15:41,228 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:15:46,231 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:15:51,232 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:15:56,233 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:16:01,235 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:16:06,236 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:16:11,242 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:16:16,248 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:16:21,251 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:16:26,252 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:16:31,256 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:16:36,260 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:16:41,262 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:16:46,263 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:16:51,265 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:16:56,268 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:17:01,270 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:17:06,272 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:17:11,273 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:17:16,273 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:17:21,275 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:17:26,277 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:17:31,279 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:17:36,281 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:17:41,282 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:17:46,286 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:17:51,287 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:17:56,288 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:18:01,291 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:18:06,293 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:18:11,296 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:18:16,307 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:18:21,315 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:18:26,320 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:18:31,322 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:18:36,325 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:18:41,327 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:18:46,330 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:18:51,337 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:18:56,339 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:19:01,341 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:19:06,343 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:19:11,348 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:19:16,349 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:19:21,351 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:19:26,365 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:19:31,367 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:19:36,369 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:19:41,373 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:19:46,375 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:19:51,376 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:19:56,379 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:20:01,381 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:20:06,383 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:20:11,386 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:20:16,392 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:20:21,396 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:20:26,398 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:20:31,399 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:20:36,401 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:20:41,402 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:20:46,404 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:20:51,444 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:20:56,446 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:21:01,448 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:21:03,976 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:163)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:2942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-10 09:21:03,980 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN
java.lang.Exception: trace
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:177)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses(DataNode.java:2922)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2017-09-10 09:21:06,450 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:21:11,452 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:21:16,453 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:21:21,455 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:21:26,460 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:21:31,469 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:21:36,471 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:21:41,473 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:21:46,475 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:21:51,482 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:21:56,490 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:22:01,491 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:22:06,492 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:22:11,495 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:22:16,497 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:22:21,499 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:22:26,502 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:22:31,506 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:22:36,515 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:22:41,518 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:22:46,519 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:22:51,521 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:22:56,524 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:23:01,526 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:23:06,529 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:23:11,532 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:23:16,535 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:23:21,537 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:23:26,540 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:23:31,542 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:23:36,545 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:23:41,547 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:23:46,548 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:23:51,550 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:23:56,553 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:24:01,555 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:24:06,556 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:24:11,557 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:24:16,559 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:24:21,560 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:24:26,561 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:24:31,565 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:24:36,566 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:24:41,568 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:24:46,569 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:24:51,577 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:24:56,579 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:25:01,581 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:25:06,583 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:25:11,586 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:25:16,588 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:25:21,595 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:25:26,596 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:25:31,598 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:25:36,601 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:25:41,603 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:25:46,605 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:25:51,610 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:25:56,614 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:26:01,616 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:26:06,621 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:26:11,622 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:26:16,624 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:26:21,626 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:26:26,628 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:26:31,629 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:26:36,631 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:26:41,633 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:26:46,634 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:26:51,635 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:26:56,636 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:27:01,638 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:27:06,640 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:27:11,642 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:27:16,644 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:27:21,645 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:27:26,647 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:27:31,649 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:27:36,656 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:27:41,657 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:27:46,659 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:27:51,661 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:27:56,664 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:28:01,673 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:28:06,679 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:28:11,681 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:28:16,683 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:28:21,688 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:28:26,691 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:28:31,692 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:28:36,694 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:28:41,695 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:28:46,696 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:28:51,699 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:28:56,701 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:29:01,703 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:29:06,706 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:29:11,708 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:29:16,708 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:29:21,709 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:29:26,712 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:29:31,714 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:29:36,718 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:29:41,719 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:29:46,721 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:29:51,723 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:29:56,724 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:30:01,726 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:30:06,732 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:30:11,733 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:30:16,735 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: slave:9000
2017-09-10 09:30:18,744 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-10 09:30:18,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2017-09-10 09:31:08,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = crubuntu
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.51.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.24.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/objenesis-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-10 09:31:08,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-10 09:31:09,818 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-10 09:31:09,928 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-10 09:31:09,928 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2017-09-10 09:31:09,938 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2017-09-10 09:31:09,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2017-09-10 09:31:09,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2017-09-10 09:31:09,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2017-09-10 09:31:09,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2017-09-10 09:31:09,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2017-09-10 09:31:10,294 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-10 09:31:10,310 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-10 09:31:10,323 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2017-09-10 09:31:10,335 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-10 09:31:10,339 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-09-10 09:31:10,340 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-10 09:31:10,340 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-10 09:31:10,369 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35099
2017-09-10 09:31:10,370 INFO org.mortbay.log: jetty-6.1.26
2017-09-10 09:31:10,638 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:35099
2017-09-10 09:31:11,144 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2017-09-10 09:31:11,150 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-10 09:31:11,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = crubuntu
2017-09-10 09:31:11,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2017-09-10 09:31:11,505 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-10 09:31:11,539 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2017-09-10 09:31:11,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2017-09-10 09:31:11,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2017-09-10 09:31:11,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2017-09-10 09:31:11,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2017-09-10 09:31:11,801 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-10 09:31:11,817 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-09-10 09:31:12,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2017-09-10 09:31:12,796 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2017-09-10 09:31:12,848 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/hadoop/input/datanode/in_use.lock acquired by nodename 20462@ubuntu
2017-09-10 09:31:12,849 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /usr/local/hadoop/input/datanode is not formatted for namespace 1644428906. Formatting...
2017-09-10 09:31:12,850 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-aa96b634-ef05-4b82-a4b2-15fb80de907c for directory /usr/local/hadoop/input/datanode
2017-09-10 09:31:12,987 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-992858576-127.0.1.1-1505060921381
2017-09-10 09:31:12,987 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381
2017-09-10 09:31:12,988 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381 is not formatted for BP-992858576-127.0.1.1-1505060921381. Formatting ...
2017-09-10 09:31:12,988 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-992858576-127.0.1.1-1505060921381 directory /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current
2017-09-10 09:31:13,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1644428906;bpid=BP-992858576-127.0.1.1-1505060921381;lv=-57;nsInfo=lv=-63;cid=CID-9064c64a-e8f2-4c23-aacf-17066518f344;nsid=1644428906;c=1505060921381;bpid=BP-992858576-127.0.1.1-1505060921381;dnuuid=null
2017-09-10 09:31:13,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 0329cedb-0b7a-4362-8a69-6a6831f14894
2017-09-10 09:31:13,179 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-aa96b634-ef05-4b82-a4b2-15fb80de907c
2017-09-10 09:31:13,179 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /usr/local/hadoop/input/datanode/current, StorageType: DISK
2017-09-10 09:31:13,199 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2017-09-10 09:31:13,216 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2017-09-10 09:31:13,216 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-992858576-127.0.1.1-1505060921381
2017-09-10 09:31:13,217 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current...
2017-09-10 09:31:13,305 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-992858576-127.0.1.1-1505060921381 on /usr/local/hadoop/input/datanode/current: 88ms
2017-09-10 09:31:13,314 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-992858576-127.0.1.1-1505060921381: 97ms
2017-09-10 09:31:13,323 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current...
2017-09-10 09:31:13,323 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/replicas doesn't exist 
2017-09-10 09:31:13,324 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current: 1ms
2017-09-10 09:31:13,326 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 9ms
2017-09-10 09:31:13,329 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode
2017-09-10 09:31:13,367 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 9/10/17 1:04 PM with interval of 21600000ms
2017-09-10 09:31:13,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-992858576-127.0.1.1-1505060921381 (Datanode Uuid 0329cedb-0b7a-4362-8a69-6a6831f14894) service to localhost/127.0.0.1:9000 beginning handshake with NN
2017-09-10 09:31:13,410 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/hadoop/input/datanode, DS-aa96b634-ef05-4b82-a4b2-15fb80de907c): finished scanning block pool BP-992858576-127.0.1.1-1505060921381
2017-09-10 09:31:13,549 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/hadoop/input/datanode, DS-aa96b634-ef05-4b82-a4b2-15fb80de907c): no suitable block pools found to scan.  Waiting 1814399780 ms.
2017-09-10 09:31:13,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-992858576-127.0.1.1-1505060921381 (Datanode Uuid 0329cedb-0b7a-4362-8a69-6a6831f14894) service to localhost/127.0.0.1:9000 successfully registered with NN
2017-09-10 09:31:13,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-09-10 09:31:14,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x36bd2ce9a70ca876,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 13 msec to generate and 124 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-09-10 09:31:14,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-992858576-127.0.1.1-1505060921381
2017-09-10 09:50:33,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741825_1001 src: /127.0.0.1:57828 dest: /127.0.0.1:50010
2017-09-10 09:50:33,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:57828, dest: /127.0.0.1:50010, bytes: 99253, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1525119694_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741825_1001, duration: 27697609
2017-09-10 09:50:33,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2017-09-10 10:22:55,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741826_1002 src: /127.0.0.1:57904 dest: /127.0.0.1:50010
2017-09-10 10:22:55,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:57904, dest: /127.0.0.1:50010, bytes: 25627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-434947663_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741826_1002, duration: 48078748
2017-09-10 10:22:55,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2017-09-10 10:27:15,070 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "ubuntu/127.0.1.1"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:154)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:456)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:577)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:771)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1786)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1155)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1052)
2017-09-10 10:27:19,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-09-10 10:27:20,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-09-10 10:27:21,016 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-10 10:27:21,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2017-09-10 11:57:59,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = crubuntu
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.51.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.24.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/objenesis-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-10 11:57:59,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-10 11:58:07,159 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-10 11:58:07,962 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-10 11:58:07,963 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2017-09-10 11:58:08,056 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2017-09-10 11:58:08,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2017-09-10 11:58:08,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2017-09-10 11:58:08,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2017-09-10 11:58:08,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2017-09-10 11:58:08,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2017-09-10 11:58:09,933 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-10 11:58:09,993 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-10 11:58:10,038 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2017-09-10 11:58:10,069 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-10 11:58:10,075 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-09-10 11:58:10,076 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-10 11:58:10,076 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-10 11:58:10,196 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 33327
2017-09-10 11:58:10,196 INFO org.mortbay.log: jetty-6.1.26
2017-09-10 11:58:10,784 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:33327
2017-09-10 11:58:12,710 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2017-09-10 11:58:12,757 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-10 11:58:13,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = crubuntu
2017-09-10 11:58:13,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2017-09-10 11:58:14,064 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-10 11:58:14,181 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2017-09-10 11:58:14,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2017-09-10 11:58:15,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2017-09-10 11:58:15,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2017-09-10 11:58:15,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2017-09-10 11:58:15,451 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-10 11:58:15,457 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-09-10 11:58:20,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2017-09-10 11:58:20,495 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2017-09-10 11:58:20,629 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/hadoop/input/datanode/in_use.lock acquired by nodename 18939@ubuntu
2017-09-10 11:58:21,147 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-992858576-127.0.1.1-1505060921381
2017-09-10 11:58:21,148 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381
2017-09-10 11:58:21,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1644428906;bpid=BP-992858576-127.0.1.1-1505060921381;lv=-57;nsInfo=lv=-63;cid=CID-9064c64a-e8f2-4c23-aacf-17066518f344;nsid=1644428906;c=1505060921381;bpid=BP-992858576-127.0.1.1-1505060921381;dnuuid=0329cedb-0b7a-4362-8a69-6a6831f14894
2017-09-10 11:58:21,896 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-aa96b634-ef05-4b82-a4b2-15fb80de907c
2017-09-10 11:58:21,897 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /usr/local/hadoop/input/datanode/current, StorageType: DISK
2017-09-10 11:58:21,982 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2017-09-10 11:58:22,093 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2017-09-10 11:58:22,093 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-992858576-127.0.1.1-1505060921381
2017-09-10 11:58:22,099 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current...
2017-09-10 11:58:22,418 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-992858576-127.0.1.1-1505060921381 on /usr/local/hadoop/input/datanode/current: 317ms
2017-09-10 11:58:22,419 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-992858576-127.0.1.1-1505060921381: 325ms
2017-09-10 11:58:22,461 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current...
2017-09-10 11:58:22,462 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/replicas doesn't exist 
2017-09-10 11:58:22,531 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current: 70ms
2017-09-10 11:58:22,532 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 85ms
2017-09-10 11:58:23,267 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/hadoop/input/datanode, DS-aa96b634-ef05-4b82-a4b2-15fb80de907c): no suitable block pools found to scan.  Waiting 1805570062 ms.
2017-09-10 11:58:23,330 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 9/10/17 12:17 PM with interval of 21600000ms
2017-09-10 11:58:23,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-992858576-127.0.1.1-1505060921381 (Datanode Uuid 0329cedb-0b7a-4362-8a69-6a6831f14894) service to localhost/127.0.0.1:9000 beginning handshake with NN
2017-09-10 11:58:24,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-992858576-127.0.1.1-1505060921381 (Datanode Uuid 0329cedb-0b7a-4362-8a69-6a6831f14894) service to localhost/127.0.0.1:9000 successfully registered with NN
2017-09-10 11:58:24,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-09-10 11:58:27,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xda50ca80df700764,  containing 1 storage report(s), of which we sent 1. The reports had 2 total blocks and used 1 RPC(s). This took 183 msec to generate and 1683 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-09-10 11:58:27,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-992858576-127.0.1.1-1505060921381
2017-09-10 12:06:38,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741827_1003 src: /127.0.0.1:58094 dest: /127.0.0.1:50010
2017-09-10 12:06:38,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:58094, dest: /127.0.0.1:50010, bytes: 4409740, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1975593141_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741827_1003, duration: 396818761
2017-09-10 12:06:38,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2017-09-10 12:06:39,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741828_1004 src: /127.0.0.1:58096 dest: /127.0.0.1:50010
2017-09-10 12:06:39,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:58096, dest: /127.0.0.1:50010, bytes: 176285, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1975593141_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741828_1004, duration: 33057810
2017-09-10 12:06:39,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2017-09-10 12:06:40,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741829_1005 src: /127.0.0.1:58098 dest: /127.0.0.1:50010
2017-09-10 12:06:40,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:58098, dest: /127.0.0.1:50010, bytes: 164368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1975593141_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741829_1005, duration: 31801434
2017-09-10 12:06:40,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2017-09-10 12:06:40,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741830_1006 src: /127.0.0.1:58100 dest: /127.0.0.1:50010
2017-09-10 12:06:40,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:58100, dest: /127.0.0.1:50010, bytes: 627814, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1975593141_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741830_1006, duration: 42091443
2017-09-10 12:06:40,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2017-09-10 12:06:48,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741831_1007 src: /127.0.0.1:58112 dest: /127.0.0.1:50010
2017-09-10 12:06:48,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:58112, dest: /127.0.0.1:50010, bytes: 108009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1975593141_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741831_1007, duration: 112148054
2017-09-10 12:06:48,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2017-09-10 12:07:22,148 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741827_1003 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741827 for deletion
2017-09-10 12:07:22,155 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741828_1004 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741828 for deletion
2017-09-10 12:07:22,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741829_1005 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741829 for deletion
2017-09-10 12:07:22,158 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2017-09-10 12:07:22,159 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741831_1007 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741831 for deletion
2017-09-10 12:07:22,159 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741827_1003 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741827
2017-09-10 12:07:22,163 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741828_1004 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741828
2017-09-10 12:07:22,165 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741829_1005 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741829
2017-09-10 12:07:22,167 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741830_1006 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741830
2017-09-10 12:07:22,168 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741831_1007 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741831
2017-09-10 12:07:49,101 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "ubuntu/127.0.1.1"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:154)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:456)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:577)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:771)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1786)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1155)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1052)
2017-09-10 12:07:53,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-09-10 12:07:54,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-09-10 12:07:55,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-09-10 12:07:56,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-09-10 12:07:56,553 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-10 12:07:56,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2017-09-16 09:57:58,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = crubuntu
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.51.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.24.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/objenesis-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-16 09:57:58,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-16 09:58:09,328 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-16 09:58:10,375 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-16 09:58:10,376 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2017-09-16 09:58:10,516 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2017-09-16 09:58:10,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2017-09-16 09:58:10,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2017-09-16 09:58:10,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2017-09-16 09:58:10,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2017-09-16 09:58:10,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2017-09-16 09:58:12,074 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-16 09:58:12,284 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-16 09:58:12,378 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2017-09-16 09:58:12,420 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-16 09:58:12,434 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-09-16 09:58:12,436 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-16 09:58:12,436 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-16 09:58:12,587 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 33851
2017-09-16 09:58:12,587 INFO org.mortbay.log: jetty-6.1.26
2017-09-16 09:58:13,848 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:33851
2017-09-16 09:58:18,930 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2017-09-16 09:58:19,051 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-16 09:58:19,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = crubuntu
2017-09-16 09:58:19,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2017-09-16 09:58:21,904 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-16 09:58:22,091 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2017-09-16 09:58:23,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2017-09-16 09:58:23,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2017-09-16 09:58:23,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2017-09-16 09:58:23,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2017-09-16 09:58:23,915 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-16 09:58:23,966 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-09-16 09:58:29,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2017-09-16 09:58:29,374 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2017-09-16 09:58:29,472 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/hadoop/input/datanode/in_use.lock acquired by nodename 2318@ubuntu
2017-09-16 09:58:29,941 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-992858576-127.0.1.1-1505060921381
2017-09-16 09:58:29,941 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381
2017-09-16 09:58:29,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1644428906;bpid=BP-992858576-127.0.1.1-1505060921381;lv=-57;nsInfo=lv=-63;cid=CID-9064c64a-e8f2-4c23-aacf-17066518f344;nsid=1644428906;c=1505060921381;bpid=BP-992858576-127.0.1.1-1505060921381;dnuuid=0329cedb-0b7a-4362-8a69-6a6831f14894
2017-09-16 09:58:30,786 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-aa96b634-ef05-4b82-a4b2-15fb80de907c
2017-09-16 09:58:30,786 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /usr/local/hadoop/input/datanode/current, StorageType: DISK
2017-09-16 09:58:30,862 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2017-09-16 09:58:31,026 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2017-09-16 09:58:31,026 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-992858576-127.0.1.1-1505060921381
2017-09-16 09:58:31,044 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current...
2017-09-16 09:58:31,546 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-992858576-127.0.1.1-1505060921381 on /usr/local/hadoop/input/datanode/current: 495ms
2017-09-16 09:58:31,546 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-992858576-127.0.1.1-1505060921381: 519ms
2017-09-16 09:58:31,600 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current...
2017-09-16 09:58:31,609 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/replicas doesn't exist 
2017-09-16 09:58:31,671 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current: 70ms
2017-09-16 09:58:31,671 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 89ms
2017-09-16 09:58:32,195 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/hadoop/input/datanode, DS-aa96b634-ef05-4b82-a4b2-15fb80de907c): no suitable block pools found to scan.  Waiting 1294361134 ms.
2017-09-16 09:58:32,328 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 9/16/17 3:55 PM with interval of 21600000ms
2017-09-16 09:58:32,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-992858576-127.0.1.1-1505060921381 (Datanode Uuid 0329cedb-0b7a-4362-8a69-6a6831f14894) service to localhost/127.0.0.1:9000 beginning handshake with NN
2017-09-16 09:58:33,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-992858576-127.0.1.1-1505060921381 (Datanode Uuid 0329cedb-0b7a-4362-8a69-6a6831f14894) service to localhost/127.0.0.1:9000 successfully registered with NN
2017-09-16 09:58:33,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-09-16 09:58:34,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xf111629eb1d4135d,  containing 1 storage report(s), of which we sent 1. The reports had 2 total blocks and used 1 RPC(s). This took 67 msec to generate and 735 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-09-16 09:58:34,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-992858576-127.0.1.1-1505060921381
2017-09-16 09:59:36,154 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "ubuntu/127.0.1.1"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:154)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:456)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:577)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:771)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1786)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1155)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1052)
2017-09-16 09:59:40,149 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-09-16 09:59:41,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-09-16 09:59:42,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-09-16 09:59:43,159 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-09-16 09:59:43,680 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-16 09:59:43,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2017-09-18 18:03:06,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = crubuntu
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.51.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.24.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/objenesis-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-18 18:03:07,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-18 18:03:21,341 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-18 18:03:22,824 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-18 18:03:22,824 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2017-09-18 18:03:22,969 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2017-09-18 18:03:22,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2017-09-18 18:03:23,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2017-09-18 18:03:23,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2017-09-18 18:03:23,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2017-09-18 18:03:23,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2017-09-18 18:03:25,398 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-18 18:03:25,489 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-18 18:03:25,562 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2017-09-18 18:03:25,627 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-18 18:03:25,636 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-09-18 18:03:25,641 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-18 18:03:25,642 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-18 18:03:25,817 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 33261
2017-09-18 18:03:25,818 INFO org.mortbay.log: jetty-6.1.26
2017-09-18 18:03:27,159 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:33261
2017-09-18 18:03:31,230 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2017-09-18 18:03:31,305 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-18 18:03:31,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = crubuntu
2017-09-18 18:03:31,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2017-09-18 18:03:35,883 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2287ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1518ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1124ms
2017-09-18 18:03:36,680 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-18 18:03:37,025 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2017-09-18 18:03:38,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2017-09-18 18:03:38,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2017-09-18 18:03:38,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2017-09-18 18:03:39,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2017-09-18 18:03:39,664 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-09-18 18:03:39,677 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-18 18:03:46,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2017-09-18 18:03:46,627 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2017-09-18 18:03:46,841 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/hadoop/input/datanode/in_use.lock acquired by nodename 3422@ubuntu
2017-09-18 18:03:47,676 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-992858576-127.0.1.1-1505060921381
2017-09-18 18:03:47,685 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381
2017-09-18 18:03:47,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1644428906;bpid=BP-992858576-127.0.1.1-1505060921381;lv=-57;nsInfo=lv=-63;cid=CID-9064c64a-e8f2-4c23-aacf-17066518f344;nsid=1644428906;c=1505060921381;bpid=BP-992858576-127.0.1.1-1505060921381;dnuuid=0329cedb-0b7a-4362-8a69-6a6831f14894
2017-09-18 18:03:49,049 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-aa96b634-ef05-4b82-a4b2-15fb80de907c
2017-09-18 18:03:49,049 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /usr/local/hadoop/input/datanode/current, StorageType: DISK
2017-09-18 18:03:49,199 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2017-09-18 18:03:49,517 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2017-09-18 18:03:49,517 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-992858576-127.0.1.1-1505060921381
2017-09-18 18:03:49,599 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current...
2017-09-18 18:03:50,182 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-992858576-127.0.1.1-1505060921381 on /usr/local/hadoop/input/datanode/current: 572ms
2017-09-18 18:03:50,185 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-992858576-127.0.1.1-1505060921381: 667ms
2017-09-18 18:03:50,302 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current...
2017-09-18 18:03:50,312 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/replicas doesn't exist 
2017-09-18 18:03:50,424 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current: 122ms
2017-09-18 18:03:50,426 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 144ms
2017-09-18 18:03:51,288 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/hadoop/input/datanode, DS-aa96b634-ef05-4b82-a4b2-15fb80de907c): no suitable block pools found to scan.  Waiting 1092442042 ms.
2017-09-18 18:03:51,455 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 9/18/17 9:00 PM with interval of 21600000ms
2017-09-18 18:03:51,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-992858576-127.0.1.1-1505060921381 (Datanode Uuid 0329cedb-0b7a-4362-8a69-6a6831f14894) service to localhost/127.0.0.1:9000 beginning handshake with NN
2017-09-18 18:03:52,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-992858576-127.0.1.1-1505060921381 (Datanode Uuid 0329cedb-0b7a-4362-8a69-6a6831f14894) service to localhost/127.0.0.1:9000 successfully registered with NN
2017-09-18 18:03:52,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-09-18 18:03:55,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x81722c5abf271ac2,  containing 1 storage report(s), of which we sent 1. The reports had 2 total blocks and used 1 RPC(s). This took 131 msec to generate and 1527 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-09-18 18:03:55,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-992858576-127.0.1.1-1505060921381
2017-09-18 18:31:54,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741832_1008 src: /127.0.0.1:41298 dest: /127.0.0.1:50010
2017-09-18 18:31:55,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41298, dest: /127.0.0.1:50010, bytes: 7, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741832_1008, duration: 527334125
2017-09-18 18:31:55,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2017-09-18 18:31:57,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741833_1009 src: /127.0.0.1:41300 dest: /127.0.0.1:50010
2017-09-18 18:31:57,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41300, dest: /127.0.0.1:50010, bytes: 42, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741833_1009, duration: 200633427
2017-09-18 18:31:57,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2017-09-18 18:32:00,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741834_1010 src: /127.0.0.1:41304 dest: /127.0.0.1:50010
2017-09-18 18:32:00,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41304, dest: /127.0.0.1:50010, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741834_1010, duration: 28388900
2017-09-18 18:32:00,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2017-09-18 18:32:02,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741835_1011 src: /127.0.0.1:41306 dest: /127.0.0.1:50010
2017-09-18 18:32:02,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41306, dest: /127.0.0.1:50010, bytes: 398, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741835_1011, duration: 165726412
2017-09-18 18:32:02,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2017-09-18 18:32:09,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741836_1012 src: /127.0.0.1:41312 dest: /127.0.0.1:50010
2017-09-18 18:32:13,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741837_1013 src: /127.0.0.1:41318 dest: /127.0.0.1:50010
2017-09-18 18:32:17,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741838_1014 src: /127.0.0.1:41320 dest: /127.0.0.1:50010
2017-09-18 18:32:17,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41318, dest: /127.0.0.1:50010, bytes: 259, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741837_1013, duration: 3387543476
2017-09-18 18:32:17,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2017-09-18 18:32:21,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741839_1015 src: /127.0.0.1:41324 dest: /127.0.0.1:50010
2017-09-18 18:32:22,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741840_1016 src: /127.0.0.1:41326 dest: /127.0.0.1:50010
2017-09-18 18:32:23,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41326, dest: /127.0.0.1:50010, bytes: 312, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741840_1016, duration: 144206560
2017-09-18 18:32:23,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2017-09-18 18:32:23,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741841_1017 src: /127.0.0.1:41328 dest: /127.0.0.1:50010
2017-09-18 18:32:23,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41328, dest: /127.0.0.1:50010, bytes: 42, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741841_1017, duration: 22531078
2017-09-18 18:32:23,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2017-09-18 18:32:24,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741842_1018 src: /127.0.0.1:41330 dest: /127.0.0.1:50010
2017-09-18 18:32:24,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41320, dest: /127.0.0.1:50010, bytes: 270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741838_1014, duration: 7693776298
2017-09-18 18:32:24,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2017-09-18 18:32:25,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741843_1019 src: /127.0.0.1:41334 dest: /127.0.0.1:50010
2017-09-18 18:32:25,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741844_1020 src: /127.0.0.1:41336 dest: /127.0.0.1:50010
2017-09-18 18:32:25,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41312, dest: /127.0.0.1:50010, bytes: 364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741836_1012, duration: 16942636663
2017-09-18 18:32:26,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2017-09-18 18:32:26,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41330, dest: /127.0.0.1:50010, bytes: 611, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741842_1018, duration: 1628734387
2017-09-18 18:32:26,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2017-09-18 18:32:27,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741845_1021 src: /127.0.0.1:41338 dest: /127.0.0.1:50010
2017-09-18 18:32:27,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41334, dest: /127.0.0.1:50010, bytes: 303, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741843_1019, duration: 1671601526
2017-09-18 18:32:27,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2017-09-18 18:32:36,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41324, dest: /127.0.0.1:50010, bytes: 3391, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741839_1015, duration: 14995007861
2017-09-18 18:32:36,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2017-09-18 18:32:41,949 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741839_1015 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741839 for deletion
2017-09-18 18:32:41,975 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741839_1015 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741839
2017-09-18 18:34:25,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741846_1022 src: /127.0.0.1:41364 dest: /127.0.0.1:50010
2017-09-18 18:34:25,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41364, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741846_1022, duration: 52014118
2017-09-18 18:34:25,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2017-09-18 18:34:27,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741847_1023 src: /127.0.0.1:41366 dest: /127.0.0.1:50010
2017-09-18 18:34:27,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41338, dest: /127.0.0.1:50010, bytes: 336, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741845_1021, duration: 120212805796
2017-09-18 18:34:27,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2017-09-18 18:34:27,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741848_1024 src: /127.0.0.1:41368 dest: /127.0.0.1:50010
2017-09-18 18:34:27,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41368, dest: /127.0.0.1:50010, bytes: 4963, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741848_1024, duration: 34787887
2017-09-18 18:34:27,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2017-09-18 18:34:29,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741849_1025 src: /127.0.0.1:41372 dest: /127.0.0.1:50010
2017-09-18 18:34:29,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41366, dest: /127.0.0.1:50010, bytes: 643, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741847_1023, duration: 1791035939
2017-09-18 18:34:29,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2017-09-18 18:34:33,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741850_1026 src: /127.0.0.1:41374 dest: /127.0.0.1:50010
2017-09-18 18:34:33,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41374, dest: /127.0.0.1:50010, bytes: 5393, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741850_1026, duration: 15473794
2017-09-18 18:34:33,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2017-09-18 18:34:33,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41336, dest: /127.0.0.1:50010, bytes: 573, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741844_1020, duration: 127981928021
2017-09-18 18:34:33,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2017-09-18 18:34:34,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41372, dest: /127.0.0.1:50010, bytes: 91, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1399592279_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741849_1025, duration: 5041449575
2017-09-18 18:34:34,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2017-09-18 18:35:29,919 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "ubuntu/127.0.1.1"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:154)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:456)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:577)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:771)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1786)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1155)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1052)
2017-09-18 18:35:33,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-09-18 18:35:34,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-09-18 18:35:35,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-09-18 18:35:36,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-09-18 18:35:37,769 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-18 18:35:37,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2017-09-18 19:52:32,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = crubuntu
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.51.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.24.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/objenesis-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-18 19:52:32,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-18 19:52:46,847 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-18 19:52:48,087 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-18 19:52:48,087 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2017-09-18 19:52:48,227 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2017-09-18 19:52:48,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2017-09-18 19:52:48,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2017-09-18 19:52:48,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2017-09-18 19:52:48,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2017-09-18 19:52:48,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2017-09-18 19:52:50,073 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-18 19:52:50,200 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-18 19:52:50,343 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2017-09-18 19:52:50,395 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-18 19:52:50,408 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-09-18 19:52:50,409 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-18 19:52:50,409 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-18 19:52:50,552 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 42643
2017-09-18 19:52:50,552 INFO org.mortbay.log: jetty-6.1.26
2017-09-18 19:52:51,874 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:42643
2017-09-18 19:52:55,098 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2017-09-18 19:52:55,195 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-18 19:52:55,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = crubuntu
2017-09-18 19:52:55,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2017-09-18 19:52:57,463 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-18 19:52:57,741 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2017-09-18 19:52:59,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2017-09-18 19:52:59,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2017-09-18 19:52:59,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2017-09-18 19:53:00,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2017-09-18 19:53:00,525 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-09-18 19:53:00,526 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-18 19:53:06,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2017-09-18 19:53:06,731 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2017-09-18 19:53:06,861 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/hadoop/input/datanode/in_use.lock acquired by nodename 6506@ubuntu
2017-09-18 19:53:07,501 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-992858576-127.0.1.1-1505060921381
2017-09-18 19:53:07,502 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381
2017-09-18 19:53:07,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1644428906;bpid=BP-992858576-127.0.1.1-1505060921381;lv=-57;nsInfo=lv=-63;cid=CID-9064c64a-e8f2-4c23-aacf-17066518f344;nsid=1644428906;c=1505060921381;bpid=BP-992858576-127.0.1.1-1505060921381;dnuuid=0329cedb-0b7a-4362-8a69-6a6831f14894
2017-09-18 19:53:08,538 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-aa96b634-ef05-4b82-a4b2-15fb80de907c
2017-09-18 19:53:08,539 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /usr/local/hadoop/input/datanode/current, StorageType: DISK
2017-09-18 19:53:08,657 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2017-09-18 19:53:08,905 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2017-09-18 19:53:08,905 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-992858576-127.0.1.1-1505060921381
2017-09-18 19:53:08,920 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current...
2017-09-18 19:53:09,268 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-992858576-127.0.1.1-1505060921381 on /usr/local/hadoop/input/datanode/current: 347ms
2017-09-18 19:53:09,268 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-992858576-127.0.1.1-1505060921381: 363ms
2017-09-18 19:53:09,337 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current...
2017-09-18 19:53:09,338 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/replicas doesn't exist 
2017-09-18 19:53:09,464 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current: 127ms
2017-09-18 19:53:09,487 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 169ms
2017-09-18 19:53:10,264 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/hadoop/input/datanode, DS-aa96b634-ef05-4b82-a4b2-15fb80de907c): no suitable block pools found to scan.  Waiting 1085883065 ms.
2017-09-18 19:53:10,398 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 9/18/17 8:54 PM with interval of 21600000ms
2017-09-18 19:53:10,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-992858576-127.0.1.1-1505060921381 (Datanode Uuid 0329cedb-0b7a-4362-8a69-6a6831f14894) service to localhost/127.0.0.1:9000 beginning handshake with NN
2017-09-18 19:53:11,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-992858576-127.0.1.1-1505060921381 (Datanode Uuid 0329cedb-0b7a-4362-8a69-6a6831f14894) service to localhost/127.0.0.1:9000 successfully registered with NN
2017-09-18 19:53:11,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-09-18 19:53:13,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x38750c9a07c9f3c2,  containing 1 storage report(s), of which we sent 1. The reports had 20 total blocks and used 1 RPC(s). This took 89 msec to generate and 1063 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-09-18 19:53:13,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-992858576-127.0.1.1-1505060921381
2017-09-18 20:54:29,487 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-992858576-127.0.1.1-1505060921381 Total blocks: 20, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2017-09-18 21:27:48,239 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-18 21:27:48,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2017-09-20 18:35:42,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = crubuntu
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.51.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.24.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/objenesis-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-20 18:35:42,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-20 18:35:50,997 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-20 18:35:52,245 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-20 18:35:52,245 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2017-09-20 18:35:52,349 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2017-09-20 18:35:52,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2017-09-20 18:35:52,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2017-09-20 18:35:52,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2017-09-20 18:35:52,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2017-09-20 18:35:52,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2017-09-20 18:35:54,634 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-20 18:35:54,712 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-20 18:35:54,785 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2017-09-20 18:35:54,830 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-20 18:35:54,850 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-09-20 18:35:54,860 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-20 18:35:54,860 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-20 18:35:55,061 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 37337
2017-09-20 18:35:55,061 INFO org.mortbay.log: jetty-6.1.26
2017-09-20 18:35:55,994 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:37337
2017-09-20 18:35:58,094 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2017-09-20 18:35:58,120 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-20 18:35:58,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = crubuntu
2017-09-20 18:35:58,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2017-09-20 18:35:58,963 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-20 18:35:59,101 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2017-09-20 18:35:59,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2017-09-20 18:35:59,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2017-09-20 18:35:59,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2017-09-20 18:36:00,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2017-09-20 18:36:00,154 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-20 18:36:00,196 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-09-20 18:36:02,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2017-09-20 18:36:02,398 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2017-09-20 18:36:02,489 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/hadoop/input/datanode/in_use.lock acquired by nodename 2413@ubuntu
2017-09-20 18:36:03,201 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-992858576-127.0.1.1-1505060921381
2017-09-20 18:36:03,202 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381
2017-09-20 18:36:03,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1644428906;bpid=BP-992858576-127.0.1.1-1505060921381;lv=-57;nsInfo=lv=-63;cid=CID-9064c64a-e8f2-4c23-aacf-17066518f344;nsid=1644428906;c=1505060921381;bpid=BP-992858576-127.0.1.1-1505060921381;dnuuid=0329cedb-0b7a-4362-8a69-6a6831f14894
2017-09-20 18:36:04,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-aa96b634-ef05-4b82-a4b2-15fb80de907c
2017-09-20 18:36:04,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /usr/local/hadoop/input/datanode/current, StorageType: DISK
2017-09-20 18:36:04,270 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2017-09-20 18:36:04,460 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2017-09-20 18:36:04,460 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-992858576-127.0.1.1-1505060921381
2017-09-20 18:36:04,467 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current...
2017-09-20 18:36:04,968 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-992858576-127.0.1.1-1505060921381 on /usr/local/hadoop/input/datanode/current: 500ms
2017-09-20 18:36:04,968 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-992858576-127.0.1.1-1505060921381: 508ms
2017-09-20 18:36:04,989 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current...
2017-09-20 18:36:04,990 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/replicas doesn't exist 
2017-09-20 18:36:05,082 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current: 93ms
2017-09-20 18:36:05,082 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 96ms
2017-09-20 18:36:05,648 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/hadoop/input/datanode, DS-aa96b634-ef05-4b82-a4b2-15fb80de907c): no suitable block pools found to scan.  Waiting 917707681 ms.
2017-09-20 18:36:05,747 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 9/20/17 9:42 PM with interval of 21600000ms
2017-09-20 18:36:05,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-992858576-127.0.1.1-1505060921381 (Datanode Uuid 0329cedb-0b7a-4362-8a69-6a6831f14894) service to localhost/127.0.0.1:9000 beginning handshake with NN
2017-09-20 18:36:06,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-992858576-127.0.1.1-1505060921381 (Datanode Uuid 0329cedb-0b7a-4362-8a69-6a6831f14894) service to localhost/127.0.0.1:9000 successfully registered with NN
2017-09-20 18:36:06,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-09-20 18:36:08,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xddff567e330989be,  containing 1 storage report(s), of which we sent 1. The reports had 20 total blocks and used 1 RPC(s). This took 48 msec to generate and 782 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-09-20 18:36:08,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-992858576-127.0.1.1-1505060921381
2017-09-20 18:53:04,148 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1082ms
No GCs detected
2017-09-20 19:12:16,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741851_1027 src: /127.0.0.1:60426 dest: /127.0.0.1:50010
2017-09-20 19:12:20,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741852_1028 src: /127.0.0.1:60430 dest: /127.0.0.1:50010
2017-09-20 19:12:25,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741853_1029 src: /127.0.0.1:60434 dest: /127.0.0.1:50010
2017-09-20 19:12:25,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60430, dest: /127.0.0.1:50010, bytes: 293, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-335580377_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741852_1028, duration: 4756881204
2017-09-20 19:12:25,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2017-09-20 19:12:28,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741854_1030 src: /127.0.0.1:60440 dest: /127.0.0.1:50010
2017-09-20 19:12:28,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60426, dest: /127.0.0.1:50010, bytes: 398, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-335580377_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741851_1027, duration: 11993835931
2017-09-20 19:12:28,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2017-09-20 19:12:28,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741855_1031 src: /127.0.0.1:60442 dest: /127.0.0.1:50010
2017-09-20 19:12:29,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60434, dest: /127.0.0.1:50010, bytes: 611, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-335580377_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741853_1029, duration: 3566215183
2017-09-20 19:12:29,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2017-09-20 19:13:15,697 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741842_1018 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
2017-09-20 19:13:15,703 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741843_1019 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2017-09-20 19:13:15,705 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741844_1020 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741844 for deletion
2017-09-20 19:13:15,706 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741845_1021 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741845 for deletion
2017-09-20 19:13:15,706 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741847_1023 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741847 for deletion
2017-09-20 19:13:15,707 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741849_1025 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741849 for deletion
2017-09-20 19:13:15,707 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741836_1012 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741836 for deletion
2017-09-20 19:13:15,708 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741837_1013 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
2017-09-20 19:13:15,709 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741838_1014 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741838 for deletion
2017-09-20 19:13:15,710 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741842_1018 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741842
2017-09-20 19:13:15,713 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741843_1019 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741843
2017-09-20 19:13:15,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741844_1020 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741844
2017-09-20 19:13:15,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741845_1021 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741845
2017-09-20 19:13:15,715 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741847_1023 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741847
2017-09-20 19:13:15,715 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741849_1025 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741849
2017-09-20 19:13:15,717 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741836_1012 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741836
2017-09-20 19:13:15,718 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741837_1013 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741837
2017-09-20 19:13:15,718 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741838_1014 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741838
2017-09-20 19:16:19,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741856_1032 src: /127.0.0.1:60482 dest: /127.0.0.1:50010
2017-09-20 19:16:19,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60482, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-335580377_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741856_1032, duration: 14469180
2017-09-20 19:16:19,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2017-09-20 19:16:19,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741857_1033 src: /127.0.0.1:60484 dest: /127.0.0.1:50010
2017-09-20 19:16:19,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60440, dest: /127.0.0.1:50010, bytes: 364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-335580377_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741854_1030, duration: 231451505459
2017-09-20 19:16:19,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2017-09-20 19:16:26,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741858_1034 src: /127.0.0.1:60486 dest: /127.0.0.1:50010
2017-09-20 19:16:26,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60486, dest: /127.0.0.1:50010, bytes: 5253, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-335580377_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741858_1034, duration: 9569547
2017-09-20 19:16:26,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741858_1034, type=LAST_IN_PIPELINE terminating
2017-09-20 19:16:26,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60442, dest: /127.0.0.1:50010, bytes: 573, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-335580377_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741855_1031, duration: 237473705647
2017-09-20 19:16:26,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2017-09-20 19:16:26,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60484, dest: /127.0.0.1:50010, bytes: 91, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-335580377_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741857_1033, duration: 7164023627
2017-09-20 19:16:26,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2017-09-22 16:15:34,004 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-992858576-127.0.1.1-1505060921381 Total blocks: 19, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2017-09-22 16:54:02,863 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1365ms
No GCs detected
2017-09-22 17:24:03,327 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2605ms
GC pool 'PS Scavenge' had collection(s): count=1 time=2619ms
2017-09-22 17:39:25,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xddff567e330989bf,  containing 1 storage report(s), of which we sent 1. The reports had 19 total blocks and used 1 RPC(s). This took 17 msec to generate and 988 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-09-22 17:39:25,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-992858576-127.0.1.1-1505060921381
2017-09-22 18:02:07,418 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1792ms
No GCs detected
2017-09-22 20:50:29,034 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1679ms
No GCs detected
2017-09-22 20:50:29,217 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-22 20:50:32,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2017-09-23 12:39:21,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = crubuntu
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.51.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.24.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/objenesis-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
2017-09-23 12:39:21,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-23 12:39:22,424 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-23 12:39:22,555 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-09-23 12:39:22,555 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2017-09-23 12:39:22,566 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2017-09-23 12:39:22,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2017-09-23 12:39:22,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2017-09-23 12:39:22,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2017-09-23 12:39:22,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2017-09-23 12:39:22,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2017-09-23 12:39:22,946 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-23 12:39:22,957 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-09-23 12:39:22,965 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2017-09-23 12:39:22,973 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-23 12:39:22,975 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-09-23 12:39:22,975 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-23 12:39:22,975 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-23 12:39:23,024 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45431
2017-09-23 12:39:23,024 INFO org.mortbay.log: jetty-6.1.26
2017-09-23 12:39:23,314 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45431
2017-09-23 12:39:24,003 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2017-09-23 12:39:24,020 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-09-23 12:39:24,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = crubuntu
2017-09-23 12:39:24,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2017-09-23 12:39:24,660 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-09-23 12:39:24,774 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2017-09-23 12:39:25,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2017-09-23 12:39:25,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2017-09-23 12:39:25,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2017-09-23 12:39:25,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2017-09-23 12:39:25,431 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-23 12:39:25,433 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-09-23 12:39:26,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2017-09-23 12:39:26,755 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2017-09-23 12:39:26,779 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/hadoop/input/datanode/in_use.lock acquired by nodename 4235@ubuntu
2017-09-23 12:39:27,117 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-992858576-127.0.1.1-1505060921381
2017-09-23 12:39:27,118 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381
2017-09-23 12:39:27,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1644428906;bpid=BP-992858576-127.0.1.1-1505060921381;lv=-57;nsInfo=lv=-63;cid=CID-9064c64a-e8f2-4c23-aacf-17066518f344;nsid=1644428906;c=1505060921381;bpid=BP-992858576-127.0.1.1-1505060921381;dnuuid=0329cedb-0b7a-4362-8a69-6a6831f14894
2017-09-23 12:39:27,305 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-aa96b634-ef05-4b82-a4b2-15fb80de907c
2017-09-23 12:39:27,305 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /usr/local/hadoop/input/datanode/current, StorageType: DISK
2017-09-23 12:39:27,323 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2017-09-23 12:39:27,346 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2017-09-23 12:39:27,346 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-992858576-127.0.1.1-1505060921381
2017-09-23 12:39:27,353 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current...
2017-09-23 12:39:27,502 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-992858576-127.0.1.1-1505060921381 on /usr/local/hadoop/input/datanode/current: 149ms
2017-09-23 12:39:27,502 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-992858576-127.0.1.1-1505060921381: 155ms
2017-09-23 12:39:27,521 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current...
2017-09-23 12:39:27,522 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/replicas doesn't exist 
2017-09-23 12:39:27,560 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-992858576-127.0.1.1-1505060921381 on volume /usr/local/hadoop/input/datanode/current: 39ms
2017-09-23 12:39:27,569 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 65ms
2017-09-23 12:39:27,849 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/hadoop/input/datanode, DS-aa96b634-ef05-4b82-a4b2-15fb80de907c): no suitable block pools found to scan.  Waiting 679905480 ms.
2017-09-23 12:39:27,888 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 9/23/17 1:33 PM with interval of 21600000ms
2017-09-23 12:39:27,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-992858576-127.0.1.1-1505060921381 (Datanode Uuid 0329cedb-0b7a-4362-8a69-6a6831f14894) service to localhost/127.0.0.1:9000 beginning handshake with NN
2017-09-23 12:39:28,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-992858576-127.0.1.1-1505060921381 (Datanode Uuid 0329cedb-0b7a-4362-8a69-6a6831f14894) service to localhost/127.0.0.1:9000 successfully registered with NN
2017-09-23 12:39:28,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-09-23 12:39:28,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xdac284a1448eae19,  containing 1 storage report(s), of which we sent 1. The reports had 19 total blocks and used 1 RPC(s). This took 12 msec to generate and 260 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-09-23 12:39:28,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-992858576-127.0.1.1-1505060921381
2017-09-23 12:49:53,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741859_1035 src: /127.0.0.1:40732 dest: /127.0.0.1:50010
2017-09-23 12:49:53,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:40732, dest: /127.0.0.1:50010, bytes: 25627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_612669893_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741859_1035, duration: 40738315
2017-09-23 12:49:53,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2017-09-23 12:55:31,589 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741859_1035 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2017-09-23 12:55:31,594 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-992858576-127.0.1.1-1505060921381 blk_1073741859_1035 file /usr/local/hadoop/input/datanode/current/BP-992858576-127.0.1.1-1505060921381/current/finalized/subdir0/subdir0/blk_1073741859
2017-09-23 12:57:53,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741860_1036 src: /127.0.0.1:40774 dest: /127.0.0.1:50010
2017-09-23 12:57:53,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:40774, dest: /127.0.0.1:50010, bytes: 25627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1119105910_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741860_1036, duration: 10798460
2017-09-23 12:57:53,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2017-09-23 13:14:20,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741861_1037 src: /127.0.0.1:40834 dest: /127.0.0.1:50010
2017-09-23 13:14:20,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:40834, dest: /127.0.0.1:50010, bytes: 925043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_733215229_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741861_1037, duration: 28812535
2017-09-23 13:14:20,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2017-09-23 13:16:02,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-992858576-127.0.1.1-1505060921381:blk_1073741862_1038 src: /127.0.0.1:40848 dest: /127.0.0.1:50010
2017-09-23 13:16:02,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:40848, dest: /127.0.0.1:50010, bytes: 141360, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1014975915_1, offset: 0, srvID: 0329cedb-0b7a-4362-8a69-6a6831f14894, blockid: BP-992858576-127.0.1.1-1505060921381:blk_1073741862_1038, duration: 35954982
2017-09-23 13:16:02,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-992858576-127.0.1.1-1505060921381:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
